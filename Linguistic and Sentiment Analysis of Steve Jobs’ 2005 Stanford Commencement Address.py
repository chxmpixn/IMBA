# -*- coding: utf-8 -*-
"""Untitled7.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IOWH1L6Y70wXnT6qba8FezcPsjegxg0p
"""

# Import necessary libraries
import nltk
import re
import string

with open("speech.rtf", "r", encoding="utf-8") as file:
    speech_text = file.read()

speech_text = speech_text.lower()

speech_text = re.sub(f"[{string.punctuation}]", "", speech_text)

speech_text = re.sub(r"\s+", " ", speech_text).strip()

print(speech_text[:300])

# Download NLTK stopwords and tokenizer
nltk.download("stopwords")
nltk.download("punkt")

from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

tokens = word_tokenize(speech_text)

stop_words = set(stopwords.words("english"))
filtered_tokens = [word for word in tokens if word.lower() not in stop_words]

print(filtered_tokens[:20])

from collections import Counter
import string

filtered_tokens = [word.lower() for word in filtered_tokens if word.isalnum()]

word_counts = Counter(filtered_tokens)

# Display the 20 most common words
print(word_counts.most_common(20))

import matplotlib.pyplot as plt
import seaborn as sns

# Extract the top 20 most common words and their counts
top_words, top_counts = zip(*word_counts.most_common(20))

plt.figure(figsize=(12, 6))
sns.barplot(x=list(top_words), y=list(top_counts), palette="viridis")

plt.xlabel("Words", fontsize=12)
plt.ylabel("Frequency", fontsize=12)
plt.title("Top 20 Most Frequent Words in Steve Jobsâ€™ Stanford Speech", fontsize=14)

plt.xticks(rotation=45)

plt.show()

from nltk.sentiment import SentimentIntensityAnalyzer

# Download VADER lexicon
nltk.download('vader_lexicon')

sia = SentimentIntensityAnalyzer()

# Compute sentiment scores for the entire speech
sentiment_scores = sia.polarity_scores(speech_text)

# Print sentiment scores
print("Sentiment Analysis Results:")
print(sentiment_scores)

import numpy as np
import matplotlib.pyplot as plt

# Split speech into segments for sentiment analysis
def split_text(text, num_segments=10):
    words = text.split()
    segment_length = len(words) // num_segments
    segments = [" ".join(words[i * segment_length:(i + 1) * segment_length]) for i in range(num_segments)]
    return segments

num_segments = 10
speech_segments = split_text(speech_text, num_segments)

sentiment_values = [sia.polarity_scores(segment)["compound"] for segment in speech_segments]

segment_labels = [f"Segment {i+1}" for i in range(num_segments)]

# Plot sentiment distribution
plt.figure(figsize=(10, 5))
plt.plot(segment_labels, sentiment_values, marker="o", linestyle="-", color="b", label="Sentiment Score")
plt.axhline(y=0, color="gray", linestyle="--", label="Neutral")
plt.xlabel("Speech Segments")
plt.ylabel("Sentiment Score (Compound)")
plt.title("Sentiment Distribution Across Steve Jobs' Speech")
plt.legend()
plt.xticks(rotation=45)
plt.show()

from wordcloud import WordCloud

# Generate word cloud from filtered tokens
wordcloud = WordCloud(width=800, height=400, background_color="white", colormap="Blues", max_words=100).generate(" ".join(filtered_tokens))

plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation="bilinear")
plt.axis("off")
plt.title("Word Cloud of Steve Jobs' Speech")
plt.show()

from PIL import Image
import numpy as np

# Load the image of Steve Jobs and convert it into a mask
mask_image = np.array(Image.open("steve_jobs.png"))

wordcloud_masked = WordCloud(width=800, height=400, background_color="white",
                             colormap="Blues", max_words=100, mask=mask_image).generate(" ".join(filtered_tokens))

plt.figure(figsize=(10, 10))
plt.imshow(wordcloud_masked, interpolation="bilinear")
plt.axis("off")
plt.title("Word Cloud of Steve Jobs' Speech (Shaped as Steve Jobs)")
plt.show()

from textblob import TextBlob

# Perform sentiment analysis
speech_blob = TextBlob(speech_text)
sentiment_score = speech_blob.sentiment.polarity  # Returns a value between -1 (negative) and 1 (positive)
subjectivity_score = speech_blob.sentiment.subjectivity  # Returns a value between 0 (objective) and 1 (subjective)

print(f"Sentiment Score: {sentiment_score:.3f}")
print(f"Subjectivity Score: {subjectivity_score:.3f}")

